{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/don05050505/don05050505/blob/main/LSTMKorean_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3UkhwioGzkIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L4qPmn465EV"
      },
      "outputs": [],
      "source": [
        "!pip install Korpora\n",
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Hannanum\n",
        "from Korpora import Korpora\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "wuAeJKx07IMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Korpora.fetch('nsmc')\n",
        "corpus = Korpora.load('nsmc')"
      ],
      "metadata": {
        "id": "weRKTcLQ7Mhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = corpus.train.texts\n",
        "train_labels = corpus.train.labels\n",
        "test_text = corpus.test.texts\n",
        "test_labels = corpus.test.labels\n",
        "Xtrain = pd.DataFrame(train_text, columns=['text'])\n",
        "ytrain = pd.DataFrame(train_labels, columns=['labels'])\n",
        "train_data = pd.concat([Xtrain, ytrain], axis=1) # x축(axis=1)\n",
        "Xtest = pd.DataFrame(test_text, columns=['text'])\n",
        "ytest = pd.DataFrame(test_labels, columns=['labels'])\n",
        "test_data = pd.concat([Xtest, ytest], axis=1) # x축(axis=1)\n",
        "print(test_data)"
      ],
      "metadata": {
        "id": "pati_75i7RrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_test_data(train, test):\n",
        "    XTrain = train['text'].values\n",
        "    YTrain = train['labels'].values\n",
        "    XTest = test['text'].values\n",
        "    YTest = test['labels'].values\n",
        "\n",
        "    return XTrain, YTrain, XTest, YTest"
      ],
      "metadata": {
        "id": "lBGU-G3B7XLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test = get_train_test_data(train_data, test_data)\n",
        "print(X_train[0], y_train[0])"
      ],
      "metadata": {
        "id": "R1BV5BWj8k-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hannanum = Hannanum()\n",
        "\n",
        "words = hannanum.morphs(X_train[0])\n",
        "print(X_train[0], words, y_train[0])"
      ],
      "metadata": {
        "id": "5NZm3HPO9NHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strop_words = ['..', '...', '....', '요', '에', '에서', '은', '는', '이', '가', '?', '.', '을', '를',\\\n",
        "               '이다', '게', '에게', '의', '로', ',' , '으로']\n",
        "XT = X_test[:1000]\n",
        "print(type(trainData))\n",
        "\n",
        "def refine(trainData):\n",
        "    maxCnt = 0\n",
        "    for i, train in enumerate(trainData):\n",
        "        words = hannanum.morphs(train) # list\n",
        "\n",
        "        for word in words:\n",
        "            if word in strop_words:\n",
        "                words.remove(word)\n",
        "\n",
        "        if len(words)>maxCnt: maxCnt = len(words)\n",
        "        string = ' '.join(words)\n",
        "        trainData[i] = string\n",
        "    return trainData, maxCnt\n",
        "\n"
      ],
      "metadata": {
        "id": "3qpph8gEASAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  한글 작업을 할 경우\n",
        "trainData, maxCnt = refine(XT)\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "vector_layer = TextVectorization(\n",
        "        max_tokens = 200000,\n",
        "        output_mode = 'int',\n",
        "        output_sequence_length = maxCnt+1)\n",
        "vector_layer.adapt(tf.cast(trainData, tf.string)) # Bag of words\n",
        "vocab_set = sorted(vector_layer.get_vocabulary())\n",
        "vocab_size = len(vocab_set)\n",
        "print(vocab_set)"
      ],
      "metadata": {
        "id": "QbHexnmvcXcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 1000\n",
        "sequence_length = 30\n",
        "lstm_length = 256\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=(1, ), dtype=tf.string))\n",
        "model.add(vector_layer)\n",
        "model.add(tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=sequence_length))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM((lstm_length))))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) # 이진분류일 때\n",
        "# model.add(tf.keras.layers.Dense(num_labels, activation='softmax')) # 다진분류일 때\n",
        "model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['accuracy']) # 이진분류일 때\n",
        "# model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrices=['accuracy']) # 다진분류일 때"
      ],
      "metadata": {
        "id": "FY0OTN77te2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = trainData\n",
        "y = y_test[:1000]\n",
        "print(X[5], y[5])"
      ],
      "metadata": {
        "id": "vrtylh0olKN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs = 10, validation_split=0.2, batch_size=30,  verbose=1, shuffle=True)"
      ],
      "metadata": {
        "id": "spwdmziCy2ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Iy-LlAr2c6ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest = X_test[1000:1100]\n",
        "ytest = y_test[1000:1100]\n",
        "\n",
        "xt, _ = refine(Xtest)\n",
        "print(xt)"
      ],
      "metadata": {
        "id": "RWizqGrLW2v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(xt, ytest, batch_size=10)"
      ],
      "metadata": {
        "id": "aVYB2Qy3onNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(xt)\n",
        "# preds = []\n",
        "# for p in pred:\n",
        "#     if p > 0.5:\n",
        "#         val =1\n",
        "#     else:\n",
        "#         val = 0\n",
        "#     preds.append(val)\n",
        "# print(preds)\n",
        "# print(ytest)\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "4qbMxChupCH1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}