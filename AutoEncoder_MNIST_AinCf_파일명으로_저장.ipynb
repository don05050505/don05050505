{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/don05050505/don05050505/blob/main/AutoEncoder_MNIST_AinCf_%ED%8C%8C%EC%9D%BC%EB%AA%85%EC%9C%BC%EB%A1%9C_%EC%A0%80%EC%9E%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Load and preprocess MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "# Define the autoencoder model\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test))\n",
        "\n",
        "# Reconstruct MNIST data using the trained autoencoder\n",
        "reconstructed_images = autoencoder.predict(x_test)\n",
        "\n",
        "# Save the reconstructed images\n",
        "np.save('MNIST_AinCf.npy', reconstructed_images)\n",
        "\n",
        "# Display original and reconstructed images\n",
        "n = 10  # Number of images to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstructed images\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(reconstructed_images[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jga9wLitqg8X",
        "outputId": "d4b21c8f-e138-4969-b8ab-282e4eb2327f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 6s 23ms/step - loss: 0.2138 - val_loss: 0.1330\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1166 - val_loss: 0.1020\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0958 - val_loss: 0.0885\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 6s 23ms/step - loss: 0.0855 - val_loss: 0.0811\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0796 - val_loss: 0.0768\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 5s 19ms/step - loss: 0.0761 - val_loss: 0.0741\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0738 - val_loss: 0.0724\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0722 - val_loss: 0.0710\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 7s 29ms/step - loss: 0.0710 - val_loss: 0.0700\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0701 - val_loss: 0.0693\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0695 - val_loss: 0.0688\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0690 - val_loss: 0.0683\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0685 - val_loss: 0.0680\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0682 - val_loss: 0.0677\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0679 - val_loss: 0.0674\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0676 - val_loss: 0.0673\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0674 - val_loss: 0.0670\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0672 - val_loss: 0.0668\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0670 - val_loss: 0.0667\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 5s 19ms/step - loss: 0.0669 - val_loss: 0.0666\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0668 - val_loss: 0.0664\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 6s 23ms/step - loss: 0.0666 - val_loss: 0.0665\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0665 - val_loss: 0.0663\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0664 - val_loss: 0.0662\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0664 - val_loss: 0.0662\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0663 - val_loss: 0.0661\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0662 - val_loss: 0.0660\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0662 - val_loss: 0.0659\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0661 - val_loss: 0.0659\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0661 - val_loss: 0.0659\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0660 - val_loss: 0.0658\n",
            "Epoch 32/50\n",
            " 64/235 [=======>......................] - ETA: 4s - loss: 0.0660"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}